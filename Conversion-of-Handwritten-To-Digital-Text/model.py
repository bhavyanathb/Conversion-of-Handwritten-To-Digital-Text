# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtCTkfJ72SazweSukMVgVOWav7TuvwtZ
"""

#importing necessary packages
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

#reading the dataset
df_num = pd.read_csv("/content/drive/MyDrive/ai project/numbers/train.csv")
df_alph = pd.read_csv("/content/drive/MyDrive/ai project/a-z/A_Z Handwritten Data/A_Z Handwritten Data.csv")

# print(df_alph.head(3))

#renaming the columns in dataset
pixel_array = ["label"]
for i in range(1,785):
  pixel_array.append(i)
df_num.columns = pixel_array
df_alph.columns = pixel_array

print(df_num.head(3))

#adding 26 to label if it corresponds to numbers, inorder to differentiate them from alphabets
df_num['label'] += 26

#concatinating the datasets
df = pd.concat([df_num, df_alph], axis = 0)

#taking the X,Y data from the dataset
X = df.drop(['label'], axis = 1)
Y = df["label"]
print(X.shape)

#converting the data type into numpy float32
X = X.to_numpy(dtype = 'float32')

#reshape the X inorder to fit into model
X_reshaped = X.reshape(-1, 28, 28,1)

#converting the data type into numpy float32
Y = Y.to_numpy(dtype = 'float32')

#defining the number of classes
num_classes = 36

#normalizing data
X = X_reshaped/255.0

#converting Y into categorical data
Y = np_utils.to_categorical(Y,num_classes=num_classes)

#creating model
model = Sequential()
model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax')) #no of classes = 36
model.summary()

#splitting the train test with ratio 1:3 whith stratify according to label
(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.75, random_state=107,shuffle=True,stratify=Y)

#compiling the model with categorical_cross entropy loss and adam optimizer
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#fitting the data and running it for 20 epochs
trained_model_history = model.fit(X_train,Y_train,validation_data=(X_test, Y_test),epochs=20, batch_size=200)

#plotting train,test accuracy
plt.plot(trained_model_history.history['accuracy'])
plt.plot(trainied_model_history.history['val_accuracy'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

#saving the model parameters
model.save("/content/drive/MyDrive/ai project/alphanumeric_0.4.h5")

